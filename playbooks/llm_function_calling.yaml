playbook:
  description: "Example: Function calling (REPL)"
  actions:
    - llm.session:
        args:
          provider: llama
          llm_args:
            model_path: /Volumes/Workspaces/models/Qwen-1_8B-Chat/ggml-model-q4_0.gguf
            chat_format: qwen-fn
        actions:
          - playbook: ./bing.yaml
        result: $session
    - repeat:
        actions:
          - shell.prompt:
              args: "Human: "
              result: $prompt
          - llm.chat:
              args:
                session: $session
                prompt: "{$prompt}"
              result: $message
          - shell.print: "AI: {$message}"
